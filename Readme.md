# Описание задачи

Написать и обучить модель-автокодировщик на датасете MNIST. Обучить модель-классификатор на латентных представлениях обученного автокодировщика.

# Установка 

Для установки среды и необходимых пакетов используется менеджер пакетов pip. Рекомендуемая версия python - 3.8.3. 

Шаги по установке среды в директорию PATH на ОС Windows:

1. cmd  
2. python3 -m venv PATH 
3. PATH/Scripts/activate
4. pip install -r requirements.txt
  
# Запуск решения

1. Скопировать проект в директорию PATH_PROJECT
2. cmd
3. <PATH>/Scripts/activate
4. jupyter notebook PATH_PROJECT
5. Открыть заметку work.ipynb в jupyter. В разделе "Используемые функции" установить значение переменных PATH_MODELS - каталог, куда будут сохраняться обученные модели; PATH_DATA - каталог, куда будут занружены данные MNIST.
6. Последовательно выполнить work.ipynb 
  
# Результаты
  В заметке были протестированы следующие сценарии:
  
  **Сценарий 1.** <br />
  *Автоэнкодер* (энкодер и декодер) реализован на базе полносвязных слоев. Количество слоев 3, функции активации RELU, размер латентного состояния - 49. Последний слой имеет функцию активации sigmoid. Функция потерь - бинарная кросс энтропия.<br />
  *Классификатор* реализован на базе 2 полносвязных слоев с функций активации RELU. Последний слой имеет функцию активации sigmoid. Функция потерь - кросс энтропия.
  
  **Сценарий 2.** <br />
  *Автоэнкодер* (энкодер и декодер) реализован на базе сверточных слоев. Количество слоев 3, функции активации RELU, размер латентного состояния - 49. Последний слой имеет функцию активации sigmoid. Функция потерь - бинарная кросс энтропия.<br />
  *Классификатор* реализован на базе 2 полносвязных слоев с функций активации RELU. Последний слой имеет функцию активации sigmoid. Функция потерь - кросс энтропия.
  
  **Сценарий 3.** <br />
  *Автоэнкодер* (энкодер и декодер) реализован на базе полносвязных слоев. Количество слоев 3, функции активации Tanh, размер латентного состояния - 49. Последний слой имеет функцию активации sigmoid. Функция потерь - бинарная кросс энтропия.<br />
  *Классификатор* реализован на базе 2 полносвязных слоев с функций активации RELU. Последний слой имеет функцию активации sigmoid. Функция потерь - кросс энтропия.
  
  **Сценарий 4.** <br />
  Реализован *вариационный автоэнкодер* (энкодер и декодер) реализован на базе 3 полносвязных слоев c функциией активации RELU, размер латентного состояния - 49. Последний слой имеет функцию активации sigmoid. Функция потерь - бинарная кросс энтропия + дивергенция KL.<br />
  *Классификатор* реализован на базе 2 полносвязных слоев с функций активации RELU. Последний слой имеет функцию активации sigmoid. Функция потерь - кросс энтропия.
  
  | № | Сценарий| Autoencoder Loss | Classificator accuracy |
  | :---: | :-------: | :---: | :---: |
  | 1| Сценарий 1 | 0.0839 | 0.90 |
  | 2 | Сценарий 2 | 0.0799| 0.93 |
  | 3 | Сценарий 3 | 0.0847 |0.93 |
  | 4 | Сценарий 4 | - |0.85 |
  
  
  # Идеи по улучшению точности классификации
  
- Реализация классификатора на базе CNN. Использование связки CNN автоэнкодер + CNN классификатор.  CNN классификатор сможет лучше интрерпретировать признаки, выявленные CNN автоэнкодером.
- Реализация вариационного автоэнкодера на базе CNN. Такая реализация может помочь выявить геометрические признаки, которые лучше описывают множество MNIST.
- Аугментация данных: добавить шум, повороты, смещения. Обучить классификатор на аугментированных данных.
- Удаление из данных для обучения цифр, написание которых не позволяет сделать вывод о значении.
